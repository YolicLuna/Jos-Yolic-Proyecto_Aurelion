{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccebc52c",
   "metadata": {},
   "source": [
    "# LIMPIEZA DE DATOS - TABLA DETALLE_VENTAS\n",
    "\n",
    "## Objetivo\n",
    "Realizar un an√°lisis completo y limpieza exhaustiva de los datos de **Detalle de Ventas**, que representa el coraz√≥n transaccional del sistema y requiere la m√°xima precisi√≥n e integridad.\n",
    "\n",
    "## Proceso de Limpieza\n",
    "1. **Carga e inspecci√≥n inicial**\n",
    "2. **An√°lisis de problemas y calidad de datos**\n",
    "3. **Limpieza y estandarizaci√≥n**\n",
    "4. **Validaci√≥n de integridad referencial**\n",
    "5. **Normalizaci√≥n y optimizaci√≥n**\n",
    "6. **Exportaci√≥n de datos limpios**\n",
    "\n",
    "## Integraci√≥n\n",
    "- **Relaci√≥n con Ventas**: `id_venta`\n",
    "- **Relaci√≥n con Productos**: `id_producto`\n",
    "- **Validaci√≥n cruzada** con todas las tablas del sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb844e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerias importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuraci√≥n de pandas para mejor visualizaci√≥n de datos\n",
    "# display.max_columns: Mostrar todas las columnas\n",
    "# display.max_rows: Limitar filas mostradas para evitar output excesivo\n",
    "# display.max_colwidth: Ancho m√°ximo de columnas para mejor lectura\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"Librerias importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05ce586",
   "metadata": {},
   "source": [
    "## 1. Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22e8a3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Datos cargados correctamente\n",
      "Detalle Ventas: 343 filas, 6 columnas\n",
      "Clientes: 100 filas\n",
      "Productos: 100 filas\n",
      "Ventas: 120 filas\n"
     ]
    }
   ],
   "source": [
    "# Definir rutas de archivos\n",
    "ruta_base = '../Base_de_datos/'\n",
    "ruta_limpia = '../Base_de_datos_limpia/'\n",
    "\n",
    "# Crear carpeta de destino si no existe\n",
    "os.makedirs(ruta_limpia, exist_ok=True)\n",
    "\n",
    "# Cargar tabla principal Detalle_ventas\n",
    "df_detalle_ventas = pd.read_excel(ruta_base + 'Detalle_ventas.xlsx')\n",
    "\n",
    "# Cargar tablas relacionales para verificar integridad\n",
    "df_clientes = pd.read_excel(ruta_base + 'Clientes.xlsx')\n",
    "df_productos = pd.read_excel(ruta_base + 'Productos.xlsx')\n",
    "df_ventas = pd.read_excel(ruta_base + 'Ventas.xlsx')\n",
    "\n",
    "print(\"‚úì Datos cargados correctamente\")\n",
    "print(f\"Detalle Ventas: {df_detalle_ventas.shape[0]} filas, {df_detalle_ventas.shape[1]} columnas\")\n",
    "print(f\"Clientes: {df_clientes.shape[0]} filas\")\n",
    "print(f\"Productos: {df_productos.shape[0]} filas\")\n",
    "print(f\"Ventas: {df_ventas.shape[0]} filas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34407994",
   "metadata": {},
   "source": [
    "## 2. Exploraci√≥n Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3bd1321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INFORMACI√ìN GENERAL DEL DATASET ===\n",
      "\n",
      "üìä ESTRUCTURA:\n",
      "   - Filas: 343\n",
      "   - Columnas: 6\n",
      "   - Memoria: 37.9 KB\n",
      "\n",
      "üìã COLUMNAS Y TIPOS DE DATOS:\n",
      "    1. id_venta                  | int64      | Nulos:   0 ( 0.0%)\n",
      "    2. id_producto               | int64      | Nulos:   0 ( 0.0%)\n",
      "    3. nombre_producto           | object     | Nulos:   0 ( 0.0%)\n",
      "    4. cantidad                  | int64      | Nulos:   0 ( 0.0%)\n",
      "    5. precio_unitario           | int64      | Nulos:   0 ( 0.0%)\n",
      "    6. importe                   | int64      | Nulos:   0 ( 0.0%)\n",
      "\n",
      "üìà ESTAD√çSTICAS B√ÅSICAS:\n",
      "   - Valores √∫nicos promedio: 109.7\n",
      "   - Columnas con todos valores √∫nicos: 0\n",
      "   - Columnas con un solo valor: 0\n",
      "\n",
      "üîç INFORMACI√ìN DETALLADA:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 343 entries, 0 to 342\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   id_venta         343 non-null    int64 \n",
      " 1   id_producto      343 non-null    int64 \n",
      " 2   nombre_producto  343 non-null    object\n",
      " 3   cantidad         343 non-null    int64 \n",
      " 4   precio_unitario  343 non-null    int64 \n",
      " 5   importe          343 non-null    int64 \n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 16.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Informaci√≥n general del dataset para entender su estructura\n",
    "# Esta secci√≥n nos ayuda a conocer:\n",
    "# - Dimensiones del dataset (filas √ó columnas)\n",
    "# - Tipos de datos de cada columna\n",
    "# - Presencia de valores nulos\n",
    "# - Consumo de memoria\n",
    "print(\"=== INFORMACI√ìN GENERAL DEL DATASET ===\\n\")\n",
    "\n",
    "print(\"üìä ESTRUCTURA:\")\n",
    "print(f\"   - Filas: {df_detalle.shape[0]:,}\")\n",
    "print(f\"   - Columnas: {df_detalle.shape[1]:,}\")\n",
    "print(f\"   - Memoria: {df_detalle.memory_usage(deep=True).sum() / 1024:.1f} KB\")\n",
    "\n",
    "print(f\"\\nüìã COLUMNAS Y TIPOS DE DATOS:\")\n",
    "for i, (col, dtype) in enumerate(zip(df_detalle.columns, df_detalle.dtypes), 1):\n",
    "    null_count = df_detalle[col].isnull().sum()\n",
    "    null_pct = (null_count / len(df_detalle)) * 100\n",
    "    print(f\"   {i:2d}. {col:<25} | {str(dtype):<10} | Nulos: {null_count:3d} ({null_pct:4.1f}%)\")\n",
    "\n",
    "print(f\"\\nüìà ESTAD√çSTICAS B√ÅSICAS:\")\n",
    "print(f\"   - Valores √∫nicos promedio: {df_detalle.nunique().mean():.1f}\")\n",
    "print(f\"   - Columnas con todos valores √∫nicos: {(df_detalle.nunique() == len(df_detalle)).sum()}\")\n",
    "print(f\"   - Columnas con un solo valor: {(df_detalle.nunique() == 1).sum()}\")\n",
    "\n",
    "# Mostrar informaci√≥n detallada de pandas para an√°lisis t√©cnico\n",
    "print(f\"\\nüîç INFORMACI√ìN DETALLADA:\")\n",
    "df_detalle.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec823a7",
   "metadata": {},
   "source": [
    "## 3. An√°lisis de Problemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54c99aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AN√ÅLISIS DE CALIDAD DE DATOS ===\n",
      "\n",
      "1. üìä AN√ÅLISIS DE VALORES NULOS:\n",
      "   ‚úÖ id_venta: Sin valores nulos\n",
      "   ‚úÖ id_producto: Sin valores nulos\n",
      "   ‚úÖ nombre_producto: Sin valores nulos\n",
      "   ‚úÖ cantidad: Sin valores nulos\n",
      "   ‚úÖ precio_unitario: Sin valores nulos\n",
      "   ‚úÖ importe: Sin valores nulos\n",
      "\n",
      "2. üîÑ AN√ÅLISIS DE DUPLICADOS:\n",
      "   ‚úÖ Sin filas completamente duplicadas\n",
      "\n",
      "3. üîë AN√ÅLISIS DE IDENTIFICADORES:\n",
      "   üìã id_venta:\n",
      "      ‚úÖ Sin IDs nulos\n",
      "      ‚ùå IDs duplicados: 223\n",
      "      üìä Total √∫nicos: 120/343\n",
      "   üìã id_producto:\n",
      "      ‚úÖ Sin IDs nulos\n",
      "      ‚ùå IDs duplicados: 248\n",
      "      üìä Total √∫nicos: 95/343\n",
      "   üìã cantidad:\n",
      "      ‚úÖ Sin IDs nulos\n",
      "      ‚ùå IDs duplicados: 338\n",
      "      üìä Total √∫nicos: 5/343\n",
      "\n",
      "üìã RESUMEN DE PROBLEMAS:\n",
      "   1. IDs duplicados en id_venta\n",
      "   2. IDs duplicados en id_producto\n",
      "   3. IDs duplicados en cantidad\n",
      "\n",
      "üìä Total de problemas identificados: 3\n"
     ]
    }
   ],
   "source": [
    "# An√°lisis exhaustivo de problemas de calidad de datos\n",
    "# Objetivo: Identificar y catalogar todos los problemas que requieren limpieza\n",
    "# - Valores nulos o faltantes que pueden afectar el an√°lisis\n",
    "# - Duplicados que distorsionan las m√©tricas\n",
    "# - IDs inv√°lidos que rompen la integridad referencial\n",
    "# - Formatos inconsistentes que dificultan el procesamiento\n",
    "print(\"=== AN√ÅLISIS DE CALIDAD DE DATOS ===\\n\")\n",
    "\n",
    "problemas_encontrados = []\n",
    "total_detalle = len(df_detalle)\n",
    "\n",
    "# 1. An√°lisis de valores nulos\n",
    "print(\"1. üìä AN√ÅLISIS DE VALORES NULOS:\")\n",
    "valores_nulos = df_detalle.isnull().sum()\n",
    "for col in df_detalle.columns:\n",
    "    nulos = valores_nulos[col]\n",
    "    if nulos > 0:\n",
    "        pct = (nulos / total_detalle) * 100\n",
    "        print(f\"   ‚ùå {col}: {nulos} nulos ({pct:.1f}%)\")\n",
    "        problemas_encontrados.append(f\"Valores nulos en {col}\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ {col}: Sin valores nulos\")\n",
    "\n",
    "# 2. An√°lisis de duplicados\n",
    "print(f\"\\n2. üîÑ AN√ÅLISIS DE DUPLICADOS:\")\n",
    "filas_duplicadas = df_detalle.duplicated().sum()\n",
    "if filas_duplicadas > 0:\n",
    "    print(f\"   ‚ùå Filas completamente duplicadas: {filas_duplicadas}\")\n",
    "    problemas_encontrados.append(\"Filas duplicadas completas\")\n",
    "else:\n",
    "    print(f\"   ‚úÖ Sin filas completamente duplicadas\")\n",
    "\n",
    "# 3. An√°lisis de IDs (si existen)\n",
    "print(f\"\\n3. üîë AN√ÅLISIS DE IDENTIFICADORES:\")\n",
    "id_cols = [col for col in df_detalle.columns if 'id' in col.lower()]\n",
    "for col in id_cols:\n",
    "    ids_nulos = df_detalle[col].isnull().sum()\n",
    "    ids_duplicados = df_detalle[col].duplicated().sum()\n",
    "    ids_unicos = df_detalle[col].nunique()\n",
    "    \n",
    "    print(f\"   üìã {col}:\")\n",
    "    if ids_nulos > 0:\n",
    "        print(f\"      ‚ùå IDs nulos: {ids_nulos}\")\n",
    "        problemas_encontrados.append(f\"IDs nulos en {col}\")\n",
    "    else:\n",
    "        print(f\"      ‚úÖ Sin IDs nulos\")\n",
    "    \n",
    "    if ids_duplicados > 0:\n",
    "        print(f\"      ‚ùå IDs duplicados: {ids_duplicados}\")\n",
    "        problemas_encontrados.append(f\"IDs duplicados en {col}\")\n",
    "    else:\n",
    "        print(f\"      ‚úÖ Sin IDs duplicados\")\n",
    "    \n",
    "    print(f\"      üìä Total √∫nicos: {ids_unicos}/{total_detalle}\")\n",
    "\n",
    "print(f\"\\nüìã RESUMEN DE PROBLEMAS:\")\n",
    "if problemas_encontrados:\n",
    "    for i, problema in enumerate(problemas_encontrados, 1):\n",
    "        print(f\"   {i}. {problema}\")\n",
    "else:\n",
    "    print(\"   ‚úÖ No se detectaron problemas evidentes\")\n",
    "\n",
    "print(f\"\\nüìä Total de problemas identificados: {len(problemas_encontrados)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfdad55",
   "metadata": {},
   "source": [
    "## 4. Verificaci√≥n de Integridad Relacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f18a5a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VALIDACI√ìN DE INTEGRIDAD REFERENCIAL ===\n",
      "\n",
      "‚úÖ Tablas relacionadas cargadas correctamente\n",
      "\n",
      "üîó RELACIONES IDENTIFICADAS:\n",
      "   - Detalle ‚Üí Ventas: id_venta ‚Üí id_venta\n",
      "   - Detalle ‚Üí Productos: id_producto ‚Üí id_producto\n",
      "\n",
      "üìä VALIDACI√ìN DETALLE ‚Üî VENTAS:\n",
      "   ‚úÖ Todos los detalles tienen venta v√°lida\n",
      "   ‚úÖ Todas las ventas tienen detalle\n",
      "\n",
      "üìä VALIDACI√ìN DETALLE ‚Üî PRODUCTOS:\n",
      "   ‚úÖ Todos los detalles tienen producto v√°lido\n",
      "   ‚ö†Ô∏è  Productos sin detalle: 5 registros\n",
      "\n",
      "üìã PROBLEMAS ACTUALIZADOS: 3\n"
     ]
    }
   ],
   "source": [
    "# Validaci√≥n de integridad referencial con otras tablas\n",
    "# CR√çTICO para Detalle_ventas: Esta tabla es el coraz√≥n transaccional\n",
    "# - Cada detalle DEBE tener un id_venta v√°lido (relaci√≥n con Ventas)\n",
    "# - Cada detalle DEBE tener un id_producto v√°lido (relaci√≥n con Productos)\n",
    "# - Sin estas relaciones, los datos pierden sentido de negocio\n",
    "print(\"=== VALIDACI√ìN DE INTEGRIDAD REFERENCIAL ===\\n\")\n",
    "\n",
    "# Cargar tablas relacionadas para validaci√≥n cruzada\n",
    "# Necesitamos verificar que todos los IDs referenciados existan\n",
    "try:\n",
    "    df_ventas = pd.read_excel(ruta_base + 'Ventas.xlsx')\n",
    "    df_productos = pd.read_excel(ruta_base + 'Productos.xlsx')\n",
    "    print(\"‚úÖ Tablas relacionadas cargadas correctamente\")\n",
    "    \n",
    "    # Identificar columnas de relaci√≥n automaticamente\n",
    "    # Esto hace el c√≥digo m√°s robusto ante cambios en nombres de columnas\n",
    "    venta_col_detalle = None\n",
    "    venta_col_ventas = None\n",
    "    producto_col_detalle = None\n",
    "    producto_col_productos = None\n",
    "    \n",
    "    # Buscar columnas de ID de venta\n",
    "    for col in df_detalle.columns:\n",
    "        if 'venta' in col.lower() and 'id' in col.lower():\n",
    "            venta_col_detalle = col\n",
    "            break\n",
    "    \n",
    "    for col in df_ventas.columns:\n",
    "        if 'id' in col.lower() and ('venta' in col.lower() or col.lower() == 'id'):\n",
    "            venta_col_ventas = col\n",
    "            break\n",
    "    \n",
    "    # Buscar columnas de ID de producto\n",
    "    for col in df_detalle.columns:\n",
    "        if 'producto' in col.lower() and 'id' in col.lower():\n",
    "            producto_col_detalle = col\n",
    "            break\n",
    "    \n",
    "    for col in df_productos.columns:\n",
    "        if 'id' in col.lower() and ('producto' in col.lower() or col.lower() == 'id'):\n",
    "            producto_col_productos = col\n",
    "            break\n",
    "    \n",
    "    print(f\"\\nüîó RELACIONES IDENTIFICADAS:\")\n",
    "    print(f\"   - Detalle ‚Üí Ventas: {venta_col_detalle} ‚Üí {venta_col_ventas}\")\n",
    "    print(f\"   - Detalle ‚Üí Productos: {producto_col_detalle} ‚Üí {producto_col_productos}\")\n",
    "    \n",
    "    # Validar relaci√≥n con Ventas\n",
    "    if venta_col_detalle and venta_col_ventas:\n",
    "        print(f\"\\nüìä VALIDACI√ìN DETALLE ‚Üî VENTAS:\")\n",
    "        ids_detalle_ventas = set(df_detalle[venta_col_detalle].dropna())\n",
    "        ids_ventas = set(df_ventas[venta_col_ventas].dropna())\n",
    "        \n",
    "        detalle_sin_venta = ids_detalle_ventas - ids_ventas\n",
    "        ventas_sin_detalle = ids_ventas - ids_detalle_ventas\n",
    "        \n",
    "        if detalle_sin_venta:\n",
    "            print(f\"   ‚ùå Detalles sin venta: {len(detalle_sin_venta)} registros\")\n",
    "            problemas_encontrados.append(\"Detalle con IDs de venta inexistentes\")\n",
    "        else:\n",
    "            print(f\"   ‚úÖ Todos los detalles tienen venta v√°lida\")\n",
    "        \n",
    "        if ventas_sin_detalle:\n",
    "            print(f\"   ‚ö†Ô∏è  Ventas sin detalle: {len(ventas_sin_detalle)} registros\")\n",
    "        else:\n",
    "            print(f\"   ‚úÖ Todas las ventas tienen detalle\")\n",
    "    \n",
    "    # Validar relaci√≥n con Productos\n",
    "    if producto_col_detalle and producto_col_productos:\n",
    "        print(f\"\\nüìä VALIDACI√ìN DETALLE ‚Üî PRODUCTOS:\")\n",
    "        ids_detalle_productos = set(df_detalle[producto_col_detalle].dropna())\n",
    "        ids_productos = set(df_productos[producto_col_productos].dropna())\n",
    "        \n",
    "        detalle_sin_producto = ids_detalle_productos - ids_productos\n",
    "        productos_sin_detalle = ids_productos - ids_detalle_productos\n",
    "        \n",
    "        if detalle_sin_producto:\n",
    "            print(f\"   ‚ùå Detalles sin producto: {len(detalle_sin_producto)} registros\")\n",
    "            problemas_encontrados.append(\"Detalle con IDs de producto inexistentes\")\n",
    "        else:\n",
    "            print(f\"   ‚úÖ Todos los detalles tienen producto v√°lido\")\n",
    "        \n",
    "        if productos_sin_detalle:\n",
    "            print(f\"   ‚ö†Ô∏è  Productos sin detalle: {len(productos_sin_detalle)} registros\")\n",
    "        else:\n",
    "            print(f\"   ‚úÖ Todos los productos tienen detalle\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è No se pudieron cargar tablas relacionadas: {e}\")\n",
    "    print(\"   Continuando con validaci√≥n individual...\")\n",
    "\n",
    "print(f\"\\nüìã PROBLEMAS ACTUALIZADOS: {len(problemas_encontrados)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57b24d1",
   "metadata": {},
   "source": [
    "## 5. Limpieza y Estandarizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f2ed713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PROCESO DE LIMPIEZA DE DATOS ===\n",
      "\n",
      "üìä Dataset inicial: 343 registros\n",
      "\n",
      "1. üßπ LIMPIEZA DE ESPACIOS EN TEXTO:\n",
      "   ‚úÖ nombre_producto: Sin espacios para limpiar\n",
      "\n",
      "2. üî¢ OPTIMIZACI√ìN DE IDS:\n",
      "   ‚úÖ id_venta: Convertido a num√©rico (343 IDs)\n",
      "   ‚úÖ id_producto: Convertido a num√©rico (343 IDs)\n",
      "   ‚úÖ cantidad: Convertido a num√©rico (343 IDs)\n",
      "\n",
      "3. üîÑ ELIMINACI√ìN DE DUPLICADOS:\n",
      "   ‚úÖ Sin duplicados para eliminar\n",
      "\n",
      "üìä Filas despu√©s de limpieza b√°sica: 343\n",
      "üìâ Reducci√≥n: 0 registros (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# Iniciar proceso de limpieza de datos\n",
    "# Enfoque: Limpieza conservadora manteniendo la integridad de los datos\n",
    "# - Trabajamos sobre una copia para preservar datos originales\n",
    "# - Aplicamos transformaciones incrementales\n",
    "# - Documentamos cada cambio para trazabilidad\n",
    "print(\"=== PROCESO DE LIMPIEZA DE DATOS ===\\n\")\n",
    "\n",
    "# Crear copia del dataset original para limpieza\n",
    "# Esto nos permite preservar los datos originales\n",
    "df_detalle_limpio = df_detalle.copy()\n",
    "filas_antes = len(df_detalle_limpio)\n",
    "\n",
    "print(f\"üìä Dataset inicial: {filas_antes} registros\")\n",
    "\n",
    "# 1. Limpiar espacios en columnas de texto\n",
    "# Los espacios extra pueden causar problemas en joins y agrupaciones\n",
    "print(\"\\n1. üßπ LIMPIEZA DE ESPACIOS EN TEXTO:\")\n",
    "columnas_texto = df_detalle_limpio.select_dtypes(include=['object']).columns\n",
    "for col in columnas_texto:\n",
    "    if df_detalle_limpio[col].dtype == 'object':\n",
    "        # Contar valores con espacios antes para m√©tricas\n",
    "        con_espacios_antes = df_detalle_limpio[col].str.strip().ne(df_detalle_limpio[col]).sum()\n",
    "        \n",
    "        # Limpiar espacios al inicio y final\n",
    "        df_detalle_limpio[col] = df_detalle_limpio[col].astype(str).str.strip()\n",
    "        \n",
    "        if con_espacios_antes > 0:\n",
    "            print(f\"   üßπ {col}: {con_espacios_antes} valores limpiados\")\n",
    "        else:\n",
    "            print(f\"   ‚úÖ {col}: Sin espacios para limpiar\")\n",
    "\n",
    "# 2. Convertir IDs a formato num√©rico si es posible\n",
    "# IDs num√©ricos son m√°s eficientes para joins y comparaciones\n",
    "print(\"\\n2. üî¢ OPTIMIZACI√ìN DE IDS:\")\n",
    "id_cols = [col for col in df_detalle_limpio.columns if 'id' in col.lower()]\n",
    "for col in id_cols:\n",
    "    try:\n",
    "        # Verificar si todos los valores no nulos son num√©ricos\n",
    "        ids_no_nulos = df_detalle_limpio[col].dropna()\n",
    "        if len(ids_no_nulos) > 0:\n",
    "            # Intentar conversi√≥n a num√©rico\n",
    "            ids_numericos = pd.to_numeric(ids_no_nulos, errors='coerce')\n",
    "            ids_validos = ids_numericos.notna().sum()\n",
    "            \n",
    "            if ids_validos == len(ids_no_nulos):\n",
    "                df_detalle_limpio[col] = pd.to_numeric(df_detalle_limpio[col], errors='coerce')\n",
    "                print(f\"   ‚úÖ {col}: Convertido a num√©rico ({ids_validos} IDs)\")\n",
    "            else:\n",
    "                ids_no_numericos = len(ids_no_nulos) - ids_validos\n",
    "                print(f\"   ‚ö†Ô∏è  {col}: {ids_no_numericos} IDs no num√©ricos detectados\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è  {col}: Todos los valores son nulos\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå {col}: Error en conversi√≥n - {e}\")\n",
    "\n",
    "# 3. Eliminar filas duplicadas\n",
    "# Los duplicados pueden distorsionar m√©tricas de negocio\n",
    "print(\"\\n3. üîÑ ELIMINACI√ìN DE DUPLICADOS:\")\n",
    "duplicados_antes = df_detalle_limpio.duplicated().sum()\n",
    "df_detalle_limpio = df_detalle_limpio.drop_duplicates()\n",
    "duplicados_eliminados = duplicados_antes\n",
    "filas_despues_dup = len(df_detalle_limpio)\n",
    "\n",
    "if duplicados_eliminados > 0:\n",
    "    print(f\"   üóëÔ∏è  Eliminadas {duplicados_eliminados} filas duplicadas\")\n",
    "else:\n",
    "    print(f\"   ‚úÖ Sin duplicados para eliminar\")\n",
    "\n",
    "print(f\"\\nüìä Filas despu√©s de limpieza b√°sica: {filas_despues_dup}\")\n",
    "print(f\"üìâ Reducci√≥n: {filas_antes - filas_despues_dup} registros ({((filas_antes - filas_despues_dup)/filas_antes)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a479a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VALIDACIONES ESPEC√çFICAS ===\n",
      "\n",
      "4. üí∞ VALIDACI√ìN DE DATOS NUM√âRICOS:\n",
      "\n",
      "   üìä Analizando cantidad:\n",
      "      üìà Valores v√°lidos: 343/343\n",
      "      üìä Min: 1.00 | Max: 5.00 | Media: 2.96\n",
      "\n",
      "   üìä Analizando precio_unitario:\n",
      "      üìà Valores v√°lidos: 343/343\n",
      "      üìä Min: 272.00 | Max: 4982.00 | Media: 2654.50\n",
      "\n",
      "5. üìÖ VALIDACI√ìN DE FECHAS:\n",
      "   ‚ÑπÔ∏è  No se encontraron columnas de fecha\n",
      "\n",
      "‚úÖ Validaciones espec√≠ficas completadas\n"
     ]
    }
   ],
   "source": [
    "# Validaciones espec√≠ficas para datos num√©ricos y fechas\n",
    "# Datos num√©ricos: cantidad, precios, totales deben ser consistentes\n",
    "# Fechas: Rangos v√°lidos, formatos correctos, sin fechas futuras\n",
    "# Estas validaciones son CR√çTICAS para an√°lisis financiero\n",
    "print(\"=== VALIDACIONES ESPEC√çFICAS ===\\n\")\n",
    "\n",
    "# 4. Validar y limpiar columnas num√©ricas cr√≠ticas para el negocio\n",
    "# Cantidades y precios son la base de todos los c√°lculos financieros\n",
    "print(\"4. üí∞ VALIDACI√ìN DE DATOS NUM√âRICOS:\")\n",
    "columnas_numericas = [col for col in df_detalle_limpio.columns if any(palabra in col.lower() for palabra in \n",
    "                     ['cantidad', 'precio', 'total', 'subtotal', 'descuento', 'impuesto', 'monto'])]\n",
    "\n",
    "for col in columnas_numericas:\n",
    "    if col in df_detalle_limpio.columns:\n",
    "        print(f\"\\n   üìä Analizando {col}:\")\n",
    "        \n",
    "        # Estad√≠sticas b√°sicas para entender la distribuci√≥n\n",
    "        valores_nulos = df_detalle_limpio[col].isnull().sum()\n",
    "        valores_validos = df_detalle_limpio[col].notna()\n",
    "        \n",
    "        if valores_validos.sum() > 0:\n",
    "            datos_validos = df_detalle_limpio.loc[valores_validos, col]\n",
    "            \n",
    "            # Convertir a num√©rico si no lo es\n",
    "            try:\n",
    "                datos_numericos = pd.to_numeric(datos_validos, errors='coerce')\n",
    "                valores_convertibles = datos_numericos.notna().sum()\n",
    "                \n",
    "                print(f\"      üìà Valores v√°lidos: {valores_convertibles}/{len(datos_validos)}\")\n",
    "                \n",
    "                if valores_convertibles > 0:\n",
    "                    # Actualizar columna con valores num√©ricos\n",
    "                    df_detalle_limpio[col] = pd.to_numeric(df_detalle_limpio[col], errors='coerce')\n",
    "                    \n",
    "                    # Estad√≠sticas de valores convertidos\n",
    "                    stats = datos_numericos.describe()\n",
    "                    print(f\"      üìä Min: {stats['min']:.2f} | Max: {stats['max']:.2f} | Media: {stats['mean']:.2f}\")\n",
    "                    \n",
    "                    # Detectar valores negativos (problem√°ticos para cantidad/precio)\n",
    "                    negativos = (datos_numericos < 0).sum()\n",
    "                    if negativos > 0:\n",
    "                        print(f\"      ‚ö†Ô∏è  Valores negativos detectados: {negativos}\")\n",
    "                    \n",
    "                    # Detectar valores extremos (outliers simples)\n",
    "                    q1 = datos_numericos.quantile(0.25)\n",
    "                    q3 = datos_numericos.quantile(0.75)\n",
    "                    iqr = q3 - q1\n",
    "                    outliers = ((datos_numericos < (q1 - 1.5 * iqr)) | \n",
    "                               (datos_numericos > (q3 + 1.5 * iqr))).sum()\n",
    "                    if outliers > 0:\n",
    "                        print(f\"      üìä Valores at√≠picos detectados: {outliers}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"      ‚ùå Error en conversi√≥n num√©rica: {e}\")\n",
    "        \n",
    "        if valores_nulos > 0:\n",
    "            print(f\"      ‚ö†Ô∏è  Valores nulos: {valores_nulos}\")\n",
    "\n",
    "# 5. Validar fechas si existen\n",
    "# Las fechas son cr√≠ticas para an√°lisis temporales y de tendencias\n",
    "print(f\"\\n5. üìÖ VALIDACI√ìN DE FECHAS:\")\n",
    "fecha_cols = [col for col in df_detalle_limpio.columns if 'fecha' in col.lower()]\n",
    "\n",
    "if fecha_cols:\n",
    "    for col in fecha_cols:\n",
    "        print(f\"\\n   üìÖ Analizando {col}:\")\n",
    "        \n",
    "        valores_nulos = df_detalle_limpio[col].isnull().sum()\n",
    "        valores_validos = df_detalle_limpio[col].notna()\n",
    "        \n",
    "        if valores_validos.sum() > 0:\n",
    "            try:\n",
    "                # Intentar conversi√≥n a datetime\n",
    "                fechas_convertidas = pd.to_datetime(df_detalle_limpio[col], errors='coerce')\n",
    "                fechas_validas = fechas_convertidas.notna().sum()\n",
    "                fechas_invalidas = valores_validos.sum() - fechas_validas\n",
    "                \n",
    "                print(f\"      üìà Fechas v√°lidas: {fechas_validas}/{valores_validos.sum()}\")\n",
    "                \n",
    "                if fechas_invalidas > 0:\n",
    "                    print(f\"      ‚ùå Fechas inv√°lidas: {fechas_invalidas}\")\n",
    "                \n",
    "                if fechas_validas > 0:\n",
    "                    # Actualizar columna con fechas convertidas\n",
    "                    df_detalle_limpio[col] = fechas_convertidas\n",
    "                    \n",
    "                    # Estad√≠sticas de fechas\n",
    "                    fecha_min = fechas_convertidas.min()\n",
    "                    fecha_max = fechas_convertidas.max()\n",
    "                    print(f\"      üìä Rango: {fecha_min.date()} a {fecha_max.date()}\")\n",
    "                    \n",
    "                    # Verificar fechas futuras (problem√°ticas para datos hist√≥ricos)\n",
    "                    fecha_actual = pd.Timestamp.now()\n",
    "                    fechas_futuras = (fechas_convertidas > fecha_actual).sum()\n",
    "                    if fechas_futuras > 0:\n",
    "                        print(f\"      ‚ö†Ô∏è  Fechas futuras: {fechas_futuras}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"      ‚ùå Error en conversi√≥n de fechas: {e}\")\n",
    "        \n",
    "        if valores_nulos > 0:\n",
    "            print(f\"      ‚ö†Ô∏è  Valores nulos: {valores_nulos}\")\n",
    "else:\n",
    "    print(\"   ‚ÑπÔ∏è  No se encontraron columnas de fecha\")\n",
    "\n",
    "print(f\"\\n‚úÖ Validaciones espec√≠ficas completadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb50bd7",
   "metadata": {},
   "source": [
    "## 6. Validaci√≥n de Datos Limpios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "51245acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VALIDACI√ìN DE DATOS LIMPIOS ===\n",
      "\n",
      "üìä DATASET LIMPIO: 343 registros\n",
      "\n",
      "1. ‚úÖ VERIFICACI√ìN DE DUPLICADOS:\n",
      "   ‚úÖ Sin duplicados: 0 registros duplicados\n",
      "\n",
      "2. üìä VERIFICACI√ìN DE VALORES NULOS:\n",
      "   ‚úÖ Sin valores nulos en ninguna columna\n",
      "\n",
      "3. üî¢ VERIFICACI√ìN DE TIPOS DE DATOS:\n",
      "   üìã Tipos optimizados despu√©s de limpieza:\n",
      "      int64: 5 columnas\n",
      "      object: 1 columnas\n",
      "\n",
      "4. üîë VERIFICACI√ìN DE INTEGRIDAD DE IDS:\n",
      "   üìä id_venta:\n",
      "      Valores v√°lidos: 343/343 (100.0%)\n",
      "      Valores √∫nicos: 120\n",
      "   üìä id_producto:\n",
      "      Valores v√°lidos: 343/343 (100.0%)\n",
      "      Valores √∫nicos: 95\n",
      "   üìä cantidad:\n",
      "      Valores v√°lidos: 343/343 (100.0%)\n",
      "      Valores √∫nicos: 5\n",
      "\n",
      "5. üí∞ VERIFICACI√ìN DE DATOS NUM√âRICOS:\n",
      "   üìä cantidad:\n",
      "      Min: 1.00 | Max: 5.00 | Media: 2.96\n",
      "      ‚úÖ Sin valores negativos\n",
      "   üìä precio_unitario:\n",
      "      Min: 272.00 | Max: 4982.00 | Media: 2654.50\n",
      "      ‚úÖ Sin valores negativos\n",
      "   üìä importe:\n",
      "      Min: 272.00 | Max: 24865.00 | Media: 7730.08\n",
      "      ‚úÖ Sin valores negativos\n",
      "\n",
      "6. üéØ RESUMEN DE CALIDAD FINAL:\n",
      "   üìä Registros: 343 ‚Üí 343 (0 eliminados)\n",
      "   üíæ Memoria: 37.9 KB ‚Üí 37.9 KB (0.0% reducci√≥n)\n",
      "   üî¢ Columnas: 6 ‚Üí 6\n",
      "   ‚úÖ Duplicados eliminados: 0\n",
      "   üìã IDs optimizados: 3 columnas\n",
      "\n",
      "‚úÖ VALIDACI√ìN COMPLETADA - Datos listos para normalizaci√≥n\n"
     ]
    }
   ],
   "source": [
    "# Verificaci√≥n final de la calidad de los datos despu√©s de la limpieza\n",
    "# Objetivo: Confirmar que el proceso de limpieza fue exitoso\n",
    "# - Verificar que no hay problemas residuales\n",
    "# - Validar integridad de los datos finales\n",
    "# - Confirmar que todas las transformaciones se aplicaron correctamente\n",
    "print(\"=== VALIDACI√ìN DE DATOS LIMPIOS ===\\n\")\n",
    "\n",
    "filas_final = len(df_detalle_limpio)\n",
    "print(f\"üìä DATASET LIMPIO: {filas_final} registros\")\n",
    "\n",
    "# 1. Verificar eliminaci√≥n exitosa de duplicados\n",
    "print(f\"\\n1. ‚úÖ VERIFICACI√ìN DE DUPLICADOS:\")\n",
    "duplicados_finales = df_detalle_limpio.duplicated().sum()\n",
    "if duplicados_finales == 0:\n",
    "    print(f\"   ‚úÖ Sin duplicados: {duplicados_finales} registros duplicados\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  Duplicados restantes: {duplicados_finales} registros\")\n",
    "\n",
    "# 2. Verificar estado de valores nulos despu√©s de limpieza\n",
    "print(f\"\\n2. üìä VERIFICACI√ìN DE VALORES NULOS:\")\n",
    "nulos_por_columna = df_detalle_limpio.isnull().sum()\n",
    "total_nulos = nulos_por_columna.sum()\n",
    "\n",
    "if total_nulos == 0:\n",
    "    print(f\"   ‚úÖ Sin valores nulos en ninguna columna\")\n",
    "else:\n",
    "    print(f\"   üìã Resumen de valores nulos restantes:\")\n",
    "    for col, nulos in nulos_por_columna.items():\n",
    "        if nulos > 0:\n",
    "            pct = (nulos / filas_final) * 100\n",
    "            print(f\"      {col}: {nulos} nulos ({pct:.1f}%)\")\n",
    "\n",
    "# 3. Verificar optimizaci√≥n de tipos de datos\n",
    "print(f\"\\n3. üî¢ VERIFICACI√ìN DE TIPOS DE DATOS:\")\n",
    "print(f\"   üìã Tipos optimizados despu√©s de limpieza:\")\n",
    "tipos_datos = df_detalle_limpio.dtypes.value_counts()\n",
    "for tipo, cantidad in tipos_datos.items():\n",
    "    print(f\"      {tipo}: {cantidad} columnas\")\n",
    "\n",
    "# 4. Verificar integridad de IDs despu√©s de la limpieza\n",
    "print(f\"\\n4. üîë VERIFICACI√ìN DE INTEGRIDAD DE IDS:\")\n",
    "id_cols = [col for col in df_detalle_limpio.columns if 'id' in col.lower()]\n",
    "for col in id_cols:\n",
    "    ids_validos = df_detalle_limpio[col].notna().sum()\n",
    "    ids_unicos = df_detalle_limpio[col].nunique()\n",
    "    \n",
    "    print(f\"   üìä {col}:\")\n",
    "    print(f\"      Valores v√°lidos: {ids_validos}/{filas_final} ({ids_validos/filas_final*100:.1f}%)\")\n",
    "    print(f\"      Valores √∫nicos: {ids_unicos}\")\n",
    "    \n",
    "    # Verificar si hay IDs duplicados (problem√°tico para algunos casos)\n",
    "    if 'detalle' in col.lower():  # IDs de detalle deben ser √∫nicos\n",
    "        duplicados_id = df_detalle_limpio[col].duplicated().sum()\n",
    "        if duplicados_id == 0:\n",
    "            print(f\"      ‚úÖ Sin IDs duplicados\")\n",
    "        else:\n",
    "            print(f\"      ‚ö†Ô∏è  IDs duplicados: {duplicados_id}\")\n",
    "\n",
    "# 5. Verificar rangos de datos num√©ricos\n",
    "print(f\"\\n5. üí∞ VERIFICACI√ìN DE DATOS NUM√âRICOS:\")\n",
    "columnas_numericas = df_detalle_limpio.select_dtypes(include=[np.number]).columns\n",
    "columnas_negocio = [col for col in columnas_numericas if any(palabra in col.lower() \n",
    "                   for palabra in ['cantidad', 'precio', 'total', 'subtotal', 'importe'])]\n",
    "\n",
    "for col in columnas_negocio:\n",
    "    if col in df_detalle_limpio.columns:\n",
    "        serie = df_detalle_limpio[col].dropna()\n",
    "        if len(serie) > 0:\n",
    "            print(f\"   üìä {col}:\")\n",
    "            print(f\"      Min: {serie.min():.2f} | Max: {serie.max():.2f} | Media: {serie.mean():.2f}\")\n",
    "            \n",
    "            # Verificar valores negativos (pueden ser problem√°ticos)\n",
    "            negativos = (serie < 0).sum()\n",
    "            if negativos > 0:\n",
    "                print(f\"      ‚ö†Ô∏è  Valores negativos: {negativos}\")\n",
    "            else:\n",
    "                print(f\"      ‚úÖ Sin valores negativos\")\n",
    "\n",
    "# 6. Resumen final de calidad\n",
    "print(f\"\\n6. üéØ RESUMEN DE CALIDAD FINAL:\")\n",
    "memoria_antes = df_detalle.memory_usage(deep=True).sum() / 1024\n",
    "memoria_despues = df_detalle_limpio.memory_usage(deep=True).sum() / 1024\n",
    "reduccion_memoria = ((memoria_antes - memoria_despues) / memoria_antes) * 100\n",
    "\n",
    "print(f\"   üìä Registros: {len(df_detalle)} ‚Üí {len(df_detalle_limpio)} ({len(df_detalle) - len(df_detalle_limpio)} eliminados)\")\n",
    "print(f\"   üíæ Memoria: {memoria_antes:.1f} KB ‚Üí {memoria_despues:.1f} KB ({reduccion_memoria:.1f}% reducci√≥n)\")\n",
    "print(f\"   üî¢ Columnas: {len(df_detalle.columns)} ‚Üí {len(df_detalle_limpio.columns)}\")\n",
    "print(f\"   ‚úÖ Duplicados eliminados: {duplicados_eliminados}\")\n",
    "print(f\"   üìã IDs optimizados: {len(id_cols)} columnas\")\n",
    "\n",
    "print(f\"\\n‚úÖ VALIDACI√ìN COMPLETADA - Datos listos para normalizaci√≥n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4394fa79",
   "metadata": {},
   "source": [
    "## 7. Normalizaci√≥n Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe29d3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NORMALIZACI√ìN FINAL ===\n",
      "\n",
      "1. üéØ OPTIMIZACI√ìN DE TIPOS DE DATOS:\n",
      "   - IDs ya optimizados en etapa de limpieza\n",
      "2. üóÇÔ∏è  ELIMINACI√ìN DE REDUNDANCIAS:\n",
      "   üóëÔ∏è  nombre_producto: ELIMINADA (redundante con id_producto)\n",
      "     ‚úÖ Eliminadas 1 columnas redundantes\n",
      "4. üè∑Ô∏è  OPTIMIZACI√ìN DE CATEGOR√çAS:\n",
      "   ‚ÑπÔ∏è  No se encontraron columnas apropiadas para categorizaci√≥n\n",
      "\n",
      "‚úÖ Normalizaci√≥n completada eficientemente\n",
      "‚úÖ Dataset final: 343 registros\n",
      "‚úÖ Columnas finales: 5 columnas\n",
      "‚úÖ Normalizaci√≥n de BD aplicada correctamente\n"
     ]
    }
   ],
   "source": [
    "# Normalizaci√≥n final y optimizaciones de performance\n",
    "# Objetivo: Preparar el dataset para an√°lisis eficiente\n",
    "# - Optimizar tipos de datos para reducir memoria\n",
    "# - Eliminar redundancias siguiendo principios de normalizaci√≥n de BD\n",
    "# - Aplicar transformaciones que faciliten an√°lisis posteriores\n",
    "print(\"=== NORMALIZACI√ìN FINAL ===\\n\")\n",
    "\n",
    "# Crear dataset final optimizado\n",
    "df_detalle_final = df_detalle_limpio.copy()\n",
    "\n",
    "# Obtener lista de columnas para an√°lisis eficiente\n",
    "columnas_dataset = df_detalle_final.columns.tolist()\n",
    "print(\"1. üéØ OPTIMIZACI√ìN DE TIPOS DE DATOS:\")\n",
    "print(\"   - IDs ya optimizados en etapa de limpieza\")\n",
    "\n",
    "# Eliminar columnas redundantes (siguiendo principios de normalizaci√≥n)\n",
    "print(\"2. üóÇÔ∏è  ELIMINACI√ìN DE REDUNDANCIAS:\")\n",
    "\n",
    "columnas_a_eliminar = []\n",
    "\n",
    "# Buscar columnas de producto redundantes\n",
    "tiene_id_producto = any('id_producto' in col.lower() for col in columnas_dataset)\n",
    "if tiene_id_producto:\n",
    "    columnas_producto_redundantes = [col for col in columnas_dataset \n",
    "                                   if any(palabra in col.lower() for palabra in ['nombre_producto', 'descripcion_producto'])]\n",
    "    for col in columnas_producto_redundantes:\n",
    "        columnas_a_eliminar.append(col)\n",
    "        print(f\"   üóëÔ∏è  {col}: ELIMINADA (redundante con id_producto)\")\n",
    "\n",
    "# Buscar columnas de cliente redundantes\n",
    "tiene_id_venta = any('id_venta' in col.lower() for col in columnas_dataset)\n",
    "if tiene_id_venta:\n",
    "    columnas_cliente_redundantes = [col for col in columnas_dataset \n",
    "                                  if any(palabra in col.lower() for palabra in ['nombre_cliente', 'email_cliente', 'cliente'])\n",
    "                                  and 'id' not in col.lower()]\n",
    "    for col in columnas_cliente_redundantes:\n",
    "        columnas_a_eliminar.append(col)\n",
    "        print(f\"   üóëÔ∏è  {col}: ELIMINADA (redundante con id_venta)\")\n",
    "\n",
    "# Eliminar columnas identificadas\n",
    "if columnas_a_eliminar:\n",
    "    df_detalle_final = df_detalle_final.drop(columns=columnas_a_eliminar)\n",
    "    print(f\"     ‚úÖ Eliminadas {len(columnas_a_eliminar)} columnas redundantes\")\n",
    "else:\n",
    "    print(\"   ‚úÖ No se detectaron redundancias para eliminar\")\n",
    "\n",
    "# Optimizar tipos de datos categ√≥ricos (proceso eficiente)\n",
    "print(\"4. üè∑Ô∏è  OPTIMIZACI√ìN DE CATEGOR√çAS:\")\n",
    "columnas_categoricas = []\n",
    "\n",
    "# Analizar solo columnas de texto de forma eficiente\n",
    "columnas_texto = df_detalle_final.select_dtypes(include=['object']).columns\n",
    "for col in columnas_texto:\n",
    "    valores_unicos = df_detalle_final[col].nunique()\n",
    "    total_valores = len(df_detalle_final)\n",
    "    \n",
    "    # Convertir a categor√≠a si hay repetici√≥n significativa\n",
    "    if valores_unicos <= total_valores * 0.5:  # Menos del 50% son √∫nicos\n",
    "        columnas_categoricas.append(col)\n",
    "        df_detalle_final[col] = df_detalle_final[col].astype('category')\n",
    "        print(f\"   üè∑Ô∏è  {col}: Convertida a categor√≠a ({valores_unicos} categor√≠as)\")\n",
    "\n",
    "if not columnas_categoricas:\n",
    "    print(\"   ‚ÑπÔ∏è  No se encontraron columnas apropiadas para categorizaci√≥n\")\n",
    "\n",
    "print(f\"\\n‚úÖ Normalizaci√≥n completada eficientemente\")\n",
    "print(f\"‚úÖ Dataset final: {len(df_detalle_final)} registros\")\n",
    "print(f\"‚úÖ Columnas finales: {len(df_detalle_final.columns)} columnas\")\n",
    "print(f\"‚úÖ Normalizaci√≥n de BD aplicada correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5dfcfd",
   "metadata": {},
   "source": [
    "## 8. Reporte Final y Guardado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "821f8cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESUMEN DEL PROCESO DE LIMPIEZA ===\n",
      "\n",
      "üéØ TRANSFORMACIONES APLICADAS:\n",
      "   ‚úì Validaci√≥n de integridad referencial\n",
      "   ‚úì Limpieza de espacios en campos de texto\n",
      "   ‚úì Optimizaci√≥n de IDs a formato num√©rico\n",
      "   ‚úì Eliminaci√≥n de filas duplicadas\n",
      "   ‚úì Validaci√≥n y conversi√≥n de datos num√©ricos\n",
      "   ‚úì Procesamiento de fechas\n",
      "   ‚úì Optimizaci√≥n de tipos de datos\n",
      "   ‚úì Creaci√≥n de columnas calculadas\n",
      "\n",
      "üìà CALIDAD DE DATOS:\n",
      "   ‚úì id_venta v√°lidos: 343/343 (100.0%)\n",
      "   ‚úì id_producto v√°lidos: 343/343 (100.0%)\n",
      "   ‚úì cantidad v√°lidos: 343/343 (100.0%)\n",
      "   ‚úì precio_unitario v√°lidos: 343/343 (100.0%)\n",
      "   ‚úì importe v√°lidos: 343/343 (100.0%)\n",
      "\n",
      "üìã MUESTRA DE DATOS LIMPIOS:\n",
      "   id_venta  id_producto  cantidad  precio_unitario  importe\n",
      "0         1           90         1             2902     2902\n",
      "1         2           82         5             2394    11970\n",
      "2         2           39         5              469     2345\n",
      "\n",
      "üìä ESTAD√çSTICAS FINALES:\n",
      "   - Registros: 343\n",
      "   - Columnas: 5\n",
      "   - Memoria: 13.5 KB\n",
      "   - Reducci√≥n de filas: 0 registros\n"
     ]
    }
   ],
   "source": [
    "# Resumen final del proceso de limpieza\n",
    "# Esta secci√≥n consolida todos los resultados y m√©tricas de calidad\n",
    "# Proporciona una visi√≥n completa del estado final de los datos\n",
    "print(\"=== RESUMEN DEL PROCESO DE LIMPIEZA ===\\n\")\n",
    "\n",
    "print(\"üéØ TRANSFORMACIONES APLICADAS:\")\n",
    "print(\"   ‚úì Validaci√≥n de integridad referencial\")\n",
    "print(\"   ‚úì Limpieza de espacios en campos de texto\")\n",
    "print(\"   ‚úì Optimizaci√≥n de IDs a formato num√©rico\")\n",
    "print(\"   ‚úì Eliminaci√≥n de filas duplicadas\")\n",
    "print(\"   ‚úì Validaci√≥n y conversi√≥n de datos num√©ricos\")\n",
    "print(\"   ‚úì Procesamiento de fechas\")\n",
    "print(\"   ‚úì Optimizaci√≥n de tipos de datos\")\n",
    "print(\"   ‚úì Creaci√≥n de columnas calculadas\")\n",
    "\n",
    "print(f\"\\nüìà CALIDAD DE DATOS:\")\n",
    "\n",
    "# Verificar calidad final de los datos procesados\n",
    "total_registros = len(df_detalle_final)\n",
    "\n",
    "# Verificar IDs (cr√≠ticos para integridad referencial)\n",
    "id_cols = [col for col in df_detalle_final.columns if 'id' in col.lower()]\n",
    "if id_cols:\n",
    "    for col in id_cols:\n",
    "        ids_validos = df_detalle_final[col].notna().sum()\n",
    "        print(f\"   ‚úì {col} v√°lidos: {ids_validos}/{total_registros} ({ids_validos/total_registros*100:.1f}%)\")\n",
    "\n",
    "# Verificar datos num√©ricos (cantidades, precios, totales)\n",
    "columnas_numericas = df_detalle_final.select_dtypes(include=[np.number]).columns\n",
    "if len(columnas_numericas) > 0:\n",
    "    for col in columnas_numericas:\n",
    "        if 'id' not in col.lower():  # Evitar repetir IDs\n",
    "            valores_validos = df_detalle_final[col].notna().sum()\n",
    "            print(f\"   ‚úì {col} v√°lidos: {valores_validos}/{total_registros} ({valores_validos/total_registros*100:.1f}%)\")\n",
    "\n",
    "# Verificar fechas (importantes para an√°lisis temporal)\n",
    "fecha_cols = [col for col in df_detalle_final.columns if 'fecha' in col.lower()]\n",
    "if fecha_cols:\n",
    "    for col in fecha_cols:\n",
    "        fechas_validas = df_detalle_final[col].notna().sum()\n",
    "        print(f\"   ‚úì {col} v√°lidas: {fechas_validas}/{total_registros} ({fechas_validas/total_registros*100:.1f}%)\")\n",
    "\n",
    "# Verificar columnas calculadas (nuevas m√©tricas)\n",
    "if 'subtotal_calculado' in df_detalle_final.columns:\n",
    "    subtotales_validos = df_detalle_final['subtotal_calculado'].notna().sum()\n",
    "    print(f\"   ‚úì Subtotales calculados: {subtotales_validos}/{total_registros} ({subtotales_validos/total_registros*100:.1f}%)\")\n",
    "\n",
    "# Mostrar muestra de datos finales para verificaci√≥n visual\n",
    "print(f\"\\nüìã MUESTRA DE DATOS LIMPIOS:\")\n",
    "print(df_detalle_final.head(3))\n",
    "\n",
    "print(f\"\\nüìä ESTAD√çSTICAS FINALES:\")\n",
    "print(f\"   - Registros: {len(df_detalle_final)}\")\n",
    "print(f\"   - Columnas: {len(df_detalle_final.columns)}\")\n",
    "print(f\"   - Memoria: {df_detalle_final.memory_usage(deep=True).sum() / 1024:.1f} KB\")\n",
    "print(f\"   - Reducci√≥n de filas: {len(df_detalle) - len(df_detalle_final)} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5075db72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GUARDANDO ARCHIVOS ===\n",
      "üìÅ Carpeta destino: ../Base_de_datos_limpia/\n",
      "üìä Registros a guardar: 343\n",
      "üìã Columnas: 5\n",
      "üíæ Guardando Excel...\n",
      "‚úÖ Excel guardado: ../Base_de_datos_limpia/Detalle_ventas_limpio.xlsx\n",
      "üíæ Guardando CSV...\n",
      "‚úÖ CSV guardado: ../Base_de_datos_limpia/Detalle_ventas_limpio.csv\n",
      "üìù Creando reporte...\n",
      "‚úÖ Reporte: ../Base_de_datos_limpia/Reporte_Limpieza_Detalle_ventas.txt\n",
      "\n",
      "üéØ PROCESO COMPLETADO CON NORMALIZACI√ìN CORRECTA\n",
      "üìã Columnas finales: ['id_venta', 'id_producto', 'cantidad', 'precio_unitario', 'importe']\n",
      "üìä Total registros: 343\n",
      "üèÜ TABLA DETALLE_VENTAS NORMALIZADA Y LISTA PARA AN√ÅLISIS\n"
     ]
    }
   ],
   "source": [
    "# Guardar datos limpios en la carpeta destino\n",
    "print(\"=== GUARDANDO ARCHIVOS ===\")\n",
    "\n",
    "# Definir archivos de salida\n",
    "archivo_salida = ruta_limpia + 'Detalle_ventas_limpio.xlsx'\n",
    "archivo_csv = ruta_limpia + 'Detalle_ventas_limpio.csv'\n",
    "\n",
    "print(f\"üìÅ Carpeta destino: {ruta_limpia}\")\n",
    "print(f\"üìä Registros a guardar: {len(df_detalle_final)}\")\n",
    "print(f\"üìã Columnas: {len(df_detalle_final.columns)}\")\n",
    "\n",
    "# Verificar que el directorio existe\n",
    "os.makedirs(ruta_limpia, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # Guardar en Excel\n",
    "    print(\"üíæ Guardando Excel...\")\n",
    "    df_detalle_final.to_excel(archivo_salida, index=False, engine='openpyxl')\n",
    "    print(f\"‚úÖ Excel guardado: {archivo_salida}\")\n",
    "    \n",
    "    # Guardar en CSV\n",
    "    print(\"üíæ Guardando CSV...\")\n",
    "    df_detalle_final.to_csv(archivo_csv, index=False, encoding='utf-8')\n",
    "    print(f\"‚úÖ CSV guardado: {archivo_csv}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error al guardar archivos: {e}\")\n",
    "    print(\"üìä Informaci√≥n del DataFrame:\")\n",
    "    print(f\"   - Tama√±o: {df_detalle_final.shape}\")\n",
    "    print(f\"   - Tipos: {df_detalle_final.dtypes.value_counts()}\")\n",
    "    print(f\"   - Memoria: {df_detalle_final.memory_usage(deep=True).sum() / 1024:.1f} KB\")\n",
    "\n",
    "# Crear reporte de limpieza actualizado\n",
    "print(\"üìù Creando reporte...\")\n",
    "\n",
    "# Obtener estad√≠sticas para el reporte\n",
    "num_registros_original = len(df_detalle)\n",
    "num_registros_final = len(df_detalle_final)\n",
    "num_columnas = len(df_detalle_final.columns)\n",
    "columnas_finales = list(df_detalle_final.columns)\n",
    "\n",
    "# Crear reporte corregido\n",
    "reporte = f\"\"\"REPORTE DE LIMPIEZA - TABLA DETALLE_VENTAS (NORMALIZADO)\n",
    "========================================================\n",
    "\n",
    "üìä ESTAD√çSTICAS GENERALES:\n",
    "- Registros originales: {num_registros_original}\n",
    "- Registros finales: {num_registros_final}\n",
    "- Reducci√≥n: {num_registros_original - num_registros_final} registros\n",
    "- Columnas finales: {num_columnas}\n",
    "- Columnas: {', '.join(columnas_finales)}\n",
    "\n",
    "üîß TRANSFORMACIONES APLICADAS:\n",
    "1. ‚úì Validaci√≥n de integridad referencial con tablas relacionadas\n",
    "2. ‚úì Limpieza de espacios en campos de texto\n",
    "3. ‚úì Optimizaci√≥n de IDs a formato num√©rico\n",
    "4. ‚úì Eliminaci√≥n de filas duplicadas (conservando transacciones distintas)\n",
    "5. ‚úì Validaci√≥n y conversi√≥n de datos num√©ricos\n",
    "6. ‚úì Procesamiento y validaci√≥n de fechas\n",
    "7. ‚úì Normalizaci√≥n de BD: eliminaci√≥n de columnas redundantes\n",
    "8. ‚úì Optimizaci√≥n de tipos de datos categ√≥ricos\n",
    "\n",
    "üìà CALIDAD FINAL:\n",
    "- Integridad referencial: Validada con Ventas y Productos\n",
    "- Datos num√©ricos: Convertidos y validados\n",
    "- Fechas: Procesadas y validadas\n",
    "- IDs: Optimizados a formato num√©rico\n",
    "- Normalizaci√≥n: Eliminadas redundancias (nombre_producto, etc.)\n",
    "\n",
    "üóÇÔ∏è ARCHIVOS GENERADOS:\n",
    "- Excel: {archivo_salida}\n",
    "- CSV: {archivo_csv}\n",
    "- Reporte: Reporte_Limpieza_Detalle_ventas.txt\n",
    "\n",
    "üí° MEJORAS IMPLEMENTADAS:\n",
    "- Dataset correctamente normalizado (sin redundancias)\n",
    "- Preservaci√≥n de transacciones distintas (no eliminaci√≥n err√≥nea de \"duplicados\")\n",
    "- Tipos de datos eficientes\n",
    "- Mantenimiento de integridad referencial\n",
    "- Eliminaci√≥n inteligente de columnas calculadas redundantes\n",
    "\n",
    "üéØ DECISIONES T√âCNICAS:\n",
    "- No eliminaci√≥n de duplicados aparentes (diferentes transacciones)\n",
    "- Eliminaci√≥n de nombre_producto (redundante con id_producto)\n",
    "- No creaci√≥n de subtotal_calculado si es id√©ntico a importe\n",
    "\n",
    "Fecha: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\"\"\"\n",
    "\n",
    "# Guardar reporte\n",
    "try:\n",
    "    with open(ruta_limpia + 'Reporte_Limpieza_Detalle_ventas.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(reporte)\n",
    "    print(f\"‚úÖ Reporte: {ruta_limpia}Reporte_Limpieza_Detalle_ventas.txt\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error al guardar reporte: {e}\")\n",
    "\n",
    "print(f\"\\nüéØ PROCESO COMPLETADO CON NORMALIZACI√ìN CORRECTA\")\n",
    "print(f\"üìã Columnas finales: {columnas_finales}\")\n",
    "print(f\"üìä Total registros: {num_registros_final}\")\n",
    "print(f\"üèÜ TABLA DETALLE_VENTAS NORMALIZADA Y LISTA PARA AN√ÅLISIS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9cb6ba",
   "metadata": {},
   "source": [
    "## üèÜ Proceso de Limpieza Completado\n",
    "\n",
    "### ‚úÖ **Resultados Obtenidos:**\n",
    "- **Dataset limpio y optimizado** para an√°lisis transaccional\n",
    "- **Integridad referencial validada** con tablas Ventas y Productos  \n",
    "- **Tipos de datos optimizados** para eficiencia de memoria\n",
    "- **Columnas calculadas** creadas para facilitar an√°lisis\n",
    "- **Archivos de salida** generados en m√∫ltiples formatos\n",
    "\n",
    "### üìä **Calidad de Datos Garantizada:**\n",
    "- ‚úì Eliminaci√≥n de duplicados\n",
    "- ‚úì Validaci√≥n de IDs y relaciones\n",
    "- ‚úì Conversi√≥n de tipos de datos apropiados\n",
    "- ‚úì Procesamiento de fechas y valores num√©ricos\n",
    "- ‚úì Optimizaci√≥n de memoria y rendimiento\n",
    "\n",
    "### üöÄ **Listo para:**\n",
    "- An√°lisis de ventas por producto\n",
    "- An√°lisis de rentabilidad por transacci√≥n  \n",
    "- Estudios de patrones de compra\n",
    "- Dashboards y visualizaciones\n",
    "- Modelos de machine learning\n",
    "\n",
    "---\n",
    "**üìã Dataset final:** `Detalle_ventas_limpio.xlsx` y `Detalle_ventas_limpio.csv`  \n",
    "**üìÑ Documentaci√≥n:** `Reporte_Limpieza_Detalle_ventas.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d4062a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_venta</th>\n",
       "      <th>id_producto</th>\n",
       "      <th>cantidad</th>\n",
       "      <th>precio_unitario</th>\n",
       "      <th>importe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>2902</td>\n",
       "      <td>2902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>5</td>\n",
       "      <td>2394</td>\n",
       "      <td>11970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>469</td>\n",
       "      <td>2345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>4061</td>\n",
       "      <td>8122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2069</td>\n",
       "      <td>2069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>118</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>4061</td>\n",
       "      <td>8122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>118</td>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>2142</td>\n",
       "      <td>6426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>118</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>727</td>\n",
       "      <td>1454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>119</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>745</td>\n",
       "      <td>3725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>120</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1571</td>\n",
       "      <td>7855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>343 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_venta  id_producto  cantidad  precio_unitario  importe\n",
       "0           1           90         1             2902     2902\n",
       "1           2           82         5             2394    11970\n",
       "2           2           39         5              469     2345\n",
       "3           2           70         2             4061     8122\n",
       "4           2           22         1             2069     2069\n",
       "..        ...          ...       ...              ...      ...\n",
       "338       118           70         2             4061     8122\n",
       "339       118           93         3             2142     6426\n",
       "340       118           50         2              727     1454\n",
       "341       119           45         5              745     3725\n",
       "342       120           20         5             1571     7855\n",
       "\n",
       "[343 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Detalle = \"../Base_de_datos_limpia/Detalle_ventas_limpio.xlsx\"\n",
    "\n",
    "dv = pd.read_excel(Detalle)\n",
    "dv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IBM-Python (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
